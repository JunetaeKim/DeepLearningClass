{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impor modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toy data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample input data (a list of sentences, where each sentence is a list of word indices)\n",
    "data = np.array([[3, 6, 9], [2, 5, 8], [1, 4, 7]])\n",
    "\n",
    "# Hyperparameters\n",
    "vocab_size = 10  # Vocabulary size (number of unique words in your dataset)\n",
    "embedding_dim = 4  # Size of the embedding vectors\n",
    "input_length = 3 # Length of the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "Embedd (Embedding)           (None, 3, 4)              40        \n",
      "=================================================================\n",
      "Total params: 40\n",
      "Trainable params: 40\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the input layer\n",
    "input_layer = Input(shape=(input_length,), dtype=\"int32\")\n",
    "\n",
    "# Add the embedding layer\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=input_length, name='Embedd')(input_layer)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=embedding_layer)\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether the size of second dimension of the data matches the input length of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape[1] == model.input[1].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return the embedding vectors\n",
    "#### (batch, input_lenght, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3, 4), dtype=float32, numpy=\n",
       "array([[[ 0.00090636, -0.04525907,  0.01140468, -0.00727352],\n",
       "        [ 0.01679579, -0.03768013,  0.01675231, -0.03288104],\n",
       "        [ 0.02741626,  0.00246184, -0.04513309,  0.03628683]],\n",
       "\n",
       "       [[ 0.03387538,  0.03149626, -0.00531118, -0.04352448],\n",
       "        [ 0.0344721 ,  0.03498758, -0.01548102, -0.02356925],\n",
       "        [-0.00263525,  0.04107567,  0.00939419, -0.04705123]],\n",
       "\n",
       "       [[-0.03991412, -0.02816613, -0.00644202,  0.03202518],\n",
       "        [-0.03499562,  0.04683853,  0.03016383,  0.01458838],\n",
       "        [ 0.04784336, -0.04316411, -0.01562294, -0.02190723]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the embedding results for each word using tf.nn.embedding_lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([-0.00134405,  0.00113857,  0.01210244, -0.04505004], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_idx = 0\n",
    "tf.nn.embedding_lookup(model.get_layer('Embedd').weights, word_idx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
