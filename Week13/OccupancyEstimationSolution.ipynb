{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ae881a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import ssl\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense, TimeDistributed, RepeatVector, SimpleRNN\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5c7d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db8925f7",
   "metadata": {},
   "source": [
    "### Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "909798f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/JunetaeKim/DeepLearningClass/main/Dataset/Occupancy_Estimation.csv'\n",
    "Occupancy = pd.read_csv(url)\n",
    "Occupancy = Occupancy.drop(columns=['Date','Time'])\n",
    "Occupancy['Room_Occupancy_Count'] = np.clip(Occupancy['Room_Occupancy_Count'], 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7cdd86f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Data description\n",
    "https://archive.ics.uci.edu/ml/datasets/Room+Occupancy+Estimation\n",
    "\n",
    "#### The experimental testbed for occupancy estimation was deployed in a 6m Ã— 4.6m room. The setup consisted of 7 sensor nodes and one edge node in a star configuration with the sensor nodes transmitting data to the edge every 30s using wireless transceivers. No HVAC systems were in use while the dataset was being collected.\n",
    "\n",
    "\n",
    "##### Time: HH:MM:SS\n",
    "##### Temperature: In degree Celsius\n",
    "##### Light: In Lux\n",
    "##### Sound: In Volts (amplifier output read by ADC)\n",
    "##### CO2: In PPM\n",
    "##### CO2 Slope: Slope of CO2 values taken in a sliding window\n",
    "##### PIR: Binary value conveying motion detection\n",
    "##### Room_Occupancy_Count: Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63181216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f497045e-63e2-4cca-b484-a437145bafbe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d41435",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(Occupancy)\n",
    "Occupancy=scaler.transform(Occupancy)\n",
    "\n",
    "Occupancy_T =  np.transpose(Occupancy, (1,0))\n",
    "FrameDAta = tf.signal.frame(Occupancy_T, 41, 1)\n",
    "FrameDAta = np.transpose(FrameDAta, (1,2,0))\n",
    "\n",
    "### Data selection for input and output \n",
    "InpData = FrameDAta[:,:40, :16] # Input features for approximately the previous 20 minutes\n",
    "TargetData = FrameDAta[:,40:, 16] # The target variable after approximately 2 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2dd05ce-31d2-4dcd-a906-14a344278c55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10089, 40, 16), (10089, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InpData.shape, TargetData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa622dda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72c10f7e",
   "metadata": {},
   "source": [
    "### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91363016",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split( InpData, TargetData, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e93c4c4-a0ce-4001-a15f-90d1dcb0eaa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "918a2535",
   "metadata": {},
   "source": [
    "### Model save directory setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d278dbcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './Results/'\n",
    "if not os.path.exists(save_path):\n",
    "    os.mkdir(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f853c63c-c4d1-4eb0-8271-e7f5017defb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "befe512a",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12318e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OccupModel ():\n",
    "    InpL = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    LSTML = LSTM(20, return_sequences=True)(InpL)\n",
    "    LSTMOut = LSTM(10, return_sequences=False)(LSTML)\n",
    "    Output = Dense(1, activation='sigmoid')(LSTMOut)\n",
    "    return Model(InpL,Output)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bad4a5ea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "76/76 [==============================] - 5s 34ms/step - loss: 0.4948 - accuracy: 0.8705 - val_loss: 0.1128 - val_accuracy: 0.9814\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.11280, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 2/200\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.1029 - accuracy: 0.9803 - val_loss: 0.0626 - val_accuracy: 0.9889\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.11280 to 0.06260, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 3/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0581 - accuracy: 0.9889 - val_loss: 0.0440 - val_accuracy: 0.9913\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.06260 to 0.04402, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 4/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0419 - accuracy: 0.9916 - val_loss: 0.0357 - val_accuracy: 0.9933\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.04402 to 0.03567, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 5/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0358 - accuracy: 0.9930 - val_loss: 0.0306 - val_accuracy: 0.9945\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03567 to 0.03057, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 6/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0332 - accuracy: 0.9928 - val_loss: 0.0260 - val_accuracy: 0.9945\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03057 to 0.02600, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 7/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0226 - accuracy: 0.9949 - val_loss: 0.0241 - val_accuracy: 0.9956\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.02600 to 0.02412, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 8/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0266 - accuracy: 0.9937 - val_loss: 0.0222 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.02412 to 0.02223, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 9/200\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.0206 - accuracy: 0.9950 - val_loss: 0.0170 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.02223 to 0.01699, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 10/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0185 - accuracy: 0.9955 - val_loss: 0.0159 - val_accuracy: 0.9964\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.01699 to 0.01585, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 11/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0164 - accuracy: 0.9966 - val_loss: 0.0167 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01585\n",
      "Epoch 12/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0215 - accuracy: 0.9945 - val_loss: 0.0286 - val_accuracy: 0.9925\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01585\n",
      "Epoch 13/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0202 - accuracy: 0.9944 - val_loss: 0.0171 - val_accuracy: 0.9960\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01585\n",
      "Epoch 14/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0160 - accuracy: 0.9955 - val_loss: 0.0147 - val_accuracy: 0.9964\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01585 to 0.01466, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 15/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0162 - accuracy: 0.9959 - val_loss: 0.0133 - val_accuracy: 0.9968\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.01466 to 0.01328, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 16/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0139 - accuracy: 0.9961 - val_loss: 0.0123 - val_accuracy: 0.9968\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.01328 to 0.01232, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 17/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0118 - accuracy: 0.9969 - val_loss: 0.0121 - val_accuracy: 0.9968\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.01232 to 0.01212, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 18/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0112 - accuracy: 0.9971 - val_loss: 0.0111 - val_accuracy: 0.9968\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01212 to 0.01109, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 19/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0109 - accuracy: 0.9966 - val_loss: 0.0103 - val_accuracy: 0.9972\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01109 to 0.01026, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 20/200\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.0117 - accuracy: 0.9969 - val_loss: 0.0102 - val_accuracy: 0.9972\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.01026 to 0.01016, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 21/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0130 - accuracy: 0.9968 - val_loss: 0.0100 - val_accuracy: 0.9968\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01016 to 0.01004, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 22/200\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0087 - val_accuracy: 0.9972\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.01004 to 0.00871, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 23/200\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.0127 - accuracy: 0.9968 - val_loss: 0.0086 - val_accuracy: 0.9972\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.00871 to 0.00857, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 24/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0088 - accuracy: 0.9978 - val_loss: 0.0081 - val_accuracy: 0.9976\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.00857 to 0.00806, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 25/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0060 - accuracy: 0.9989 - val_loss: 0.0085 - val_accuracy: 0.9976\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.00806\n",
      "Epoch 26/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0077 - accuracy: 0.9981 - val_loss: 0.0073 - val_accuracy: 0.9976\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.00806 to 0.00735, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 27/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0079 - accuracy: 0.9986 - val_loss: 0.0074 - val_accuracy: 0.9976\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.00735\n",
      "Epoch 28/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0087 - accuracy: 0.9982 - val_loss: 0.0065 - val_accuracy: 0.9980\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.00735 to 0.00647, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 29/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0075 - accuracy: 0.9980 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.00647 to 0.00622, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 30/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0075 - accuracy: 0.9984 - val_loss: 0.0061 - val_accuracy: 0.9980\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.00622 to 0.00613, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 31/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0087 - accuracy: 0.9977 - val_loss: 0.0063 - val_accuracy: 0.9980\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.00613\n",
      "Epoch 32/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 0.0054 - val_accuracy: 0.9980\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.00613 to 0.00543, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 33/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0058 - accuracy: 0.9989 - val_loss: 0.0053 - val_accuracy: 0.9984\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00543 to 0.00529, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 34/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.0049 - val_accuracy: 0.9980\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.00529 to 0.00494, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 35/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0066 - accuracy: 0.9985 - val_loss: 0.0057 - val_accuracy: 0.9980\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00494\n",
      "Epoch 36/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.0052 - val_accuracy: 0.9984\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00494\n",
      "Epoch 37/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9984\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.00494 to 0.00423, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 38/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 0.9984\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00423\n",
      "Epoch 39/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0047 - accuracy: 0.9988 - val_loss: 0.0043 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.00423\n",
      "Epoch 40/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0080 - accuracy: 0.9982 - val_loss: 0.0045 - val_accuracy: 0.9984\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.00423\n",
      "Epoch 41/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0071 - accuracy: 0.9989 - val_loss: 0.0043 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.00423\n",
      "Epoch 42/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0032 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.00423 to 0.00317, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 43/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.00317 to 0.00306, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 44/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0029 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.00306 to 0.00290, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 45/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.0034 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.00290\n",
      "Epoch 46/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0057 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.00290\n",
      "Epoch 47/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0102 - accuracy: 0.9973 - val_loss: 0.0030 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.00290\n",
      "Epoch 48/200\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0031 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.00290\n",
      "Epoch 49/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0039 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.00290\n",
      "Epoch 50/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.00290\n",
      "Epoch 51/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.00290 to 0.00212, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 52/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.0031 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.00212\n",
      "Epoch 53/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0029 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.00212\n",
      "Epoch 54/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0019 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.00212 to 0.00192, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 55/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0059 - accuracy: 0.9986 - val_loss: 0.0024 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.00192\n",
      "Epoch 56/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.00192 to 0.00182, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 57/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 0.0028 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.00182\n",
      "Epoch 58/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.00182\n",
      "Epoch 59/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.00182\n",
      "Epoch 60/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0018 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.00182 to 0.00178, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 61/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.00178\n",
      "Epoch 62/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.00178\n",
      "Epoch 63/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0017 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.00178 to 0.00170, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 64/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.00170 to 0.00156, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 65/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.00156 to 0.00129, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 66/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 0.9990 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.00129\n",
      "Epoch 67/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.00129\n",
      "Epoch 68/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.00129\n",
      "Epoch 69/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.00129\n",
      "Epoch 70/200\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.00129\n",
      "Epoch 71/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 0.9995 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.00129\n",
      "Epoch 72/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.00129\n",
      "Epoch 73/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.00129 to 0.00121, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 74/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.00121\n",
      "Epoch 75/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0046 - accuracy: 0.9991 - val_loss: 0.0012 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.00121 to 0.00119, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 76/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.00119\n",
      "Epoch 77/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.0019 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.00119\n",
      "Epoch 78/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0044 - accuracy: 0.9991 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.00119\n",
      "Epoch 79/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.00119\n",
      "Epoch 80/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0033 - accuracy: 0.9991 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.00119\n",
      "Epoch 81/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.00119\n",
      "Epoch 82/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0028 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.00119\n",
      "Epoch 83/200\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0033 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.00119\n",
      "Epoch 84/200\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 0.0024 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.00119\n",
      "Epoch 85/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.00119\n",
      "Epoch 86/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0115 - val_accuracy: 0.9952\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.00119\n",
      "Epoch 87/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0058 - accuracy: 0.9987 - val_loss: 0.0022 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.00119\n",
      "Epoch 88/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0019 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00088: val_loss did not improve from 0.00119\n",
      "Epoch 89/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0014 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.00119\n",
      "Epoch 90/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.00119\n",
      "Epoch 91/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0023 - accuracy: 0.9994 - val_loss: 0.0025 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.00119\n",
      "Epoch 92/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.00119\n",
      "Epoch 93/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0027 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.00119\n",
      "Epoch 94/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 0.9988 - val_loss: 7.2029e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.00119 to 0.00072, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 95/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0030 - accuracy: 0.9993 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.00072\n",
      "Epoch 96/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 8.9375e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.00072\n",
      "Epoch 97/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0014 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.00072\n",
      "Epoch 98/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.00072\n",
      "Epoch 99/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0047 - val_accuracy: 0.9980\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.00072\n",
      "Epoch 100/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0051 - accuracy: 0.9989 - val_loss: 6.3896e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.00072 to 0.00064, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 101/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 8.4937e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00101: val_loss did not improve from 0.00064\n",
      "Epoch 102/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00102: val_loss did not improve from 0.00064\n",
      "Epoch 103/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0043 - accuracy: 0.9989 - val_loss: 0.0023 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00103: val_loss did not improve from 0.00064\n",
      "Epoch 104/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0015 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00104: val_loss did not improve from 0.00064\n",
      "Epoch 105/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0018 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00105: val_loss did not improve from 0.00064\n",
      "Epoch 106/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00106: val_loss did not improve from 0.00064\n",
      "Epoch 107/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 7.1606e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00107: val_loss did not improve from 0.00064\n",
      "Epoch 108/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00108: val_loss did not improve from 0.00064\n",
      "Epoch 109/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 6.3726e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00109: val_loss improved from 0.00064 to 0.00064, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 110/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00110: val_loss did not improve from 0.00064\n",
      "Epoch 111/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 9.1452e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00111: val_loss did not improve from 0.00064\n",
      "Epoch 112/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 9.3353e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00112: val_loss did not improve from 0.00064\n",
      "Epoch 113/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0035 - accuracy: 0.9993 - val_loss: 0.0020 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00113: val_loss did not improve from 0.00064\n",
      "Epoch 114/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0022 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00114: val_loss did not improve from 0.00064\n",
      "Epoch 115/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 8.1092e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00115: val_loss did not improve from 0.00064\n",
      "Epoch 116/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00116: val_loss did not improve from 0.00064\n",
      "Epoch 117/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 5.7320e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00117: val_loss improved from 0.00064 to 0.00057, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 118/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0013 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00118: val_loss did not improve from 0.00057\n",
      "Epoch 119/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 0.0018 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00119: val_loss did not improve from 0.00057\n",
      "Epoch 120/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0015 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00120: val_loss did not improve from 0.00057\n",
      "Epoch 121/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0043 - accuracy: 0.9991 - val_loss: 6.1499e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00121: val_loss did not improve from 0.00057\n",
      "Epoch 122/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 7.1077e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00122: val_loss did not improve from 0.00057\n",
      "Epoch 123/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0018 - accuracy: 0.9993 - val_loss: 0.0019 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00123: val_loss did not improve from 0.00057\n",
      "Epoch 124/200\n",
      "76/76 [==============================] - 1s 11ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 4.6705e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00124: val_loss improved from 0.00057 to 0.00047, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 125/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 6.5100e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00125: val_loss did not improve from 0.00047\n",
      "Epoch 126/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 5.0760e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00126: val_loss did not improve from 0.00047\n",
      "Epoch 127/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 5.0352e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00127: val_loss did not improve from 0.00047\n",
      "Epoch 128/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 9.1971e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00128: val_loss did not improve from 0.00047\n",
      "Epoch 129/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0021 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00129: val_loss did not improve from 0.00047\n",
      "Epoch 130/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00130: val_loss did not improve from 0.00047\n",
      "Epoch 131/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0029 - val_accuracy: 0.9984\n",
      "\n",
      "Epoch 00131: val_loss did not improve from 0.00047\n",
      "Epoch 132/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0015 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00132: val_loss did not improve from 0.00047\n",
      "Epoch 133/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0027 - accuracy: 0.9994 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00133: val_loss did not improve from 0.00047\n",
      "Epoch 134/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00134: val_loss did not improve from 0.00047\n",
      "Epoch 135/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0017 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00135: val_loss did not improve from 0.00047\n",
      "Epoch 136/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0012 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00136: val_loss did not improve from 0.00047\n",
      "Epoch 137/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0019 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.00047\n",
      "Epoch 138/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0015 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00138: val_loss did not improve from 0.00047\n",
      "Epoch 139/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00139: val_loss did not improve from 0.00047\n",
      "Epoch 140/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 8.9537e-04 - accuracy: 0.9999 - val_loss: 0.0022 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00140: val_loss did not improve from 0.00047\n",
      "Epoch 141/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0017 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00141: val_loss did not improve from 0.00047\n",
      "Epoch 142/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00142: val_loss did not improve from 0.00047\n",
      "Epoch 143/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 9.2343e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00143: val_loss did not improve from 0.00047\n",
      "Epoch 144/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 9.0727e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00144: val_loss did not improve from 0.00047\n",
      "Epoch 145/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0049 - accuracy: 0.9987 - val_loss: 9.2163e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00145: val_loss did not improve from 0.00047\n",
      "Epoch 146/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00146: val_loss did not improve from 0.00047\n",
      "Epoch 147/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00147: val_loss did not improve from 0.00047\n",
      "Epoch 148/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 7.3169e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00148: val_loss did not improve from 0.00047\n",
      "Epoch 149/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00149: val_loss did not improve from 0.00047\n",
      "Epoch 150/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 8.6401e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00150: val_loss did not improve from 0.00047\n",
      "Epoch 151/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0065 - val_accuracy: 0.9976\n",
      "\n",
      "Epoch 00151: val_loss did not improve from 0.00047\n",
      "Epoch 152/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0034 - accuracy: 0.9988 - val_loss: 0.0026 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00152: val_loss did not improve from 0.00047\n",
      "Epoch 153/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 0.9999 - val_loss: 0.0018 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00153: val_loss did not improve from 0.00047\n",
      "Epoch 154/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0016 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00154: val_loss did not improve from 0.00047\n",
      "Epoch 155/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 7.7085e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00155: val_loss did not improve from 0.00047\n",
      "Epoch 156/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00156: val_loss did not improve from 0.00047\n",
      "Epoch 157/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00157: val_loss did not improve from 0.00047\n",
      "Epoch 158/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0028 - accuracy: 0.9997 - val_loss: 0.0027 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00158: val_loss did not improve from 0.00047\n",
      "Epoch 159/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0016 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00159: val_loss did not improve from 0.00047\n",
      "Epoch 160/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 6.3206e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00160: val_loss did not improve from 0.00047\n",
      "Epoch 161/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 9.7144e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00161: val_loss did not improve from 0.00047\n",
      "Epoch 162/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 4.6540e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00162: val_loss improved from 0.00047 to 0.00047, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 163/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 9.9524e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00163: val_loss did not improve from 0.00047\n",
      "Epoch 164/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0031 - accuracy: 0.9993 - val_loss: 7.5454e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00164: val_loss did not improve from 0.00047\n",
      "Epoch 165/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 6.9127e-04 - accuracy: 0.9999 - val_loss: 9.6183e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00165: val_loss did not improve from 0.00047\n",
      "Epoch 166/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0025 - accuracy: 0.9993 - val_loss: 6.4001e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00166: val_loss did not improve from 0.00047\n",
      "Epoch 167/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 5.2644e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00167: val_loss did not improve from 0.00047\n",
      "Epoch 168/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 7.3099e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00168: val_loss did not improve from 0.00047\n",
      "Epoch 169/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 7.5430e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00169: val_loss did not improve from 0.00047\n",
      "Epoch 170/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 6.2330e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00170: val_loss did not improve from 0.00047\n",
      "Epoch 171/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 9.6910e-04 - accuracy: 0.9999 - val_loss: 0.0016 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00171: val_loss did not improve from 0.00047\n",
      "Epoch 172/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 7.2103e-04 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00172: val_loss did not improve from 0.00047\n",
      "Epoch 173/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0022 - accuracy: 0.9997 - val_loss: 9.9198e-04 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00173: val_loss did not improve from 0.00047\n",
      "Epoch 174/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0021 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00174: val_loss did not improve from 0.00047\n",
      "Epoch 175/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0014 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00175: val_loss did not improve from 0.00047\n",
      "Epoch 176/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00176: val_loss did not improve from 0.00047\n",
      "Epoch 177/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0015 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00177: val_loss did not improve from 0.00047\n",
      "Epoch 178/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 7.2919e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00178: val_loss did not improve from 0.00047\n",
      "Epoch 179/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 6.4364e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00179: val_loss did not improve from 0.00047\n",
      "Epoch 180/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 9.1028e-04 - accuracy: 0.9997 - val_loss: 0.0014 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00180: val_loss did not improve from 0.00047\n",
      "Epoch 181/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 6.4609e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00181: val_loss did not improve from 0.00047\n",
      "Epoch 182/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 8.8843e-04 - accuracy: 0.9998 - val_loss: 0.0022 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00182: val_loss did not improve from 0.00047\n",
      "Epoch 183/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0010 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00183: val_loss did not improve from 0.00047\n",
      "Epoch 184/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00184: val_loss did not improve from 0.00047\n",
      "Epoch 185/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 6.7543e-04 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00185: val_loss did not improve from 0.00047\n",
      "Epoch 186/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 9.5762e-04 - accuracy: 0.9999 - val_loss: 0.0023 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00186: val_loss did not improve from 0.00047\n",
      "Epoch 187/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 9.9039e-04 - accuracy: 0.9997 - val_loss: 0.0021 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00187: val_loss did not improve from 0.00047\n",
      "Epoch 188/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 9.4238e-04 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00188: val_loss did not improve from 0.00047\n",
      "Epoch 189/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0020 - accuracy: 0.9996 - val_loss: 0.0011 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00189: val_loss did not improve from 0.00047\n",
      "Epoch 190/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 5.1508e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00190: val_loss did not improve from 0.00047\n",
      "Epoch 191/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0015 - accuracy: 0.9998 - val_loss: 0.0011 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00191: val_loss did not improve from 0.00047\n",
      "Epoch 192/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 3.2284e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00192: val_loss improved from 0.00047 to 0.00032, saving model to ./Results\\Occup.hdf5\n",
      "Epoch 193/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 4.6978e-04 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00193: val_loss did not improve from 0.00032\n",
      "Epoch 194/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0016 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00194: val_loss did not improve from 0.00032\n",
      "Epoch 195/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0024 - accuracy: 0.9995 - val_loss: 4.8765e-04 - val_accuracy: 1.0000\n",
      "\n",
      "Epoch 00195: val_loss did not improve from 0.00032\n",
      "Epoch 196/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0021 - val_accuracy: 0.9988\n",
      "\n",
      "Epoch 00196: val_loss did not improve from 0.00032\n",
      "Epoch 197/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0012 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00197: val_loss did not improve from 0.00032\n",
      "Epoch 198/200\n",
      "76/76 [==============================] - 1s 10ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 9.9673e-04 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00198: val_loss did not improve from 0.00032\n",
      "Epoch 199/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0025 - accuracy: 0.9996 - val_loss: 9.3173e-04 - val_accuracy: 0.9992\n",
      "\n",
      "Epoch 00199: val_loss did not improve from 0.00032\n",
      "Epoch 200/200\n",
      "76/76 [==============================] - 1s 9ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0014 - val_accuracy: 0.9996\n",
      "\n",
      "Epoch 00200: val_loss did not improve from 0.00032\n"
     ]
    }
   ],
   "source": [
    "### Model checkpoint\n",
    "ModelSaveSameName = save_path+'Occup.hdf5'\n",
    "ModelSave = ModelCheckpoint(filepath=ModelSaveSameName, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "### Model Early stop\n",
    "EarlyStop = EarlyStopping(monitor='val_loss', patience=100)\n",
    "\n",
    "OccupM = OccupModel()\n",
    "OccupM.compile(loss=tf.losses.binary_crossentropy, optimizer='adam', metrics =['accuracy'])\n",
    "OccupMHist = OccupM.fit(X_train, Y_train, validation_data=(X_test,Y_test), epochs=200, batch_size=100,  verbose=1, callbacks=[ModelSave, EarlyStop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b357fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "372a9a21",
   "metadata": {},
   "source": [
    "### Model weight load and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76ebe03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before loading weights\n",
      "9/9 [==============================] - 1s 5ms/step - loss: 0.6816 - accuracy: 0.8225\n",
      "[0.6819075345993042, 0.8192628026008606]\n",
      "\n",
      "After loading weights\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 3.2303e-04 - accuracy: 1.0000\n",
      "[0.00032303232001140714, 1.0]\n"
     ]
    }
   ],
   "source": [
    "OccupM = OccupModel()\n",
    "OccupM.compile(loss=tf.losses.binary_crossentropy, optimizer='adam', metrics =['accuracy'])\n",
    "print('Before loading weights')\n",
    "print(OccupM.evaluate(X_test,Y_test, batch_size=300 ))\n",
    "print()\n",
    "\n",
    "OccupM.load_weights(ModelSaveSameName)\n",
    "print('After loading weights')\n",
    "print(OccupM.evaluate(X_test,Y_test, batch_size=300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2750f02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a2c4ea0",
   "metadata": {},
   "source": [
    "### Plot loss graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77c277b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(OccupMHist.history['loss'], label='Tr', marker='.')\n",
    "plt.plot(OccupMHist.history['val_loss'], label='Val', marker='.')\n",
    "plt.legend() \n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3fab55",
   "metadata": {},
   "source": [
    "### Prediction example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97d505ea-4ba5-48d1-80b3-043501e776a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.], dtype=float32), array([2067,  456], dtype=int64))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred = OccupM.predict(X_test, batch_size=300 )\n",
    "np.unique(np.round(Pred, 0), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2507f782",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
